{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3705b59",
   "metadata": {},
   "source": [
    "## Import libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4448976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow imports\n",
    "# may differs from version to versions\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# OpenCV\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508273bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors to draw rectangles in BGR\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1696011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv object that will detect faces for us\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6acbd22",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7f391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to face classification\n",
    "# model was created in me_not_me_classifier.ipynb notebook\n",
    "model_name = 'face_classifier_MobileNet_15.h5'\n",
    "\n",
    "face_classifier = keras.models.load_model(f'models/{model_name}')\n",
    "class_names = ['me', 'not_me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85dea71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_image(img, x, y, w, h, k=0.1):\n",
    "    '''\n",
    "    Function, that return cropped image from 'img'\n",
    "    If k=0 returns image, cropped from (x, y) (top left) to (x+w, y+h) (bottom right)\n",
    "    If k!=0 returns image, cropped from (x-k*w, y-k*h) to (x+k*w, y+(1+k)*h)\n",
    "    After getting the desired image resize it to 250x250.\n",
    "    And converts to tensor with shape (1, 250, 250, 3)\n",
    "\n",
    "    Parameters:\n",
    "        img (array-like, 2D): The original image\n",
    "        x (int): x coordinate of the upper-left corner\n",
    "        y (int): y coordinate of the upper-left corner\n",
    "        w (int): Width of the desired image\n",
    "        h (int): Height of the desired image\n",
    "        k (float): The coefficient of expansion of the image\n",
    "\n",
    "    Returns:\n",
    "        image (tensor with shape (1, 250, 250, 3))\n",
    "    '''\n",
    "\n",
    "    # The next code block checks that coordinates will be non-negative\n",
    "    # (in case if desired image is located in top left corner)\n",
    "    if x - k*w > 0:\n",
    "        start_x = int(x - k*w)\n",
    "    else:\n",
    "        start_x = x\n",
    "    if y - k*h > 0:\n",
    "        start_y = int(y - k*h)\n",
    "    else:\n",
    "        start_y = y\n",
    "\n",
    "    end_x = int(x + (1 + k)*w)\n",
    "    end_y = int(y + (1 + k)*h)\n",
    "\n",
    "    face_image = img[start_y:end_y,\n",
    "                     start_x:end_x]\n",
    "    face_image = tf.image.resize(face_image, [250, 250])\n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    face_image = np.expand_dims(face_image, axis=0)\n",
    "    return face_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf1580",
   "metadata": {},
   "source": [
    "## Streaming Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06ec543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to the camera was successfully obtained\n",
      "Streaming started - to quit press ESC\n",
      "Streaming ended\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)  # webcamera\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Unable to access the camera\")\n",
    "else:\n",
    "    print(\"Access to the camera was successfully obtained\")\n",
    "\n",
    "print(\"Streaming started - to quit press ESC\")\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # for each face on the image detected by OpenCV\n",
    "        # get extended image of this face\n",
    "        face_image = get_extended_image(frame, x, y, w, h, 0.5)\n",
    "\n",
    "        # classify face and draw a rectangle around the face\n",
    "        # green for positive class and red for negative\n",
    "        result = face_classifier.predict(face_image)\n",
    "        prediction = class_names[np.array(\n",
    "            result[0]).argmax(axis=0)]  # predicted class\n",
    "        confidence = np.array(result[0]).max(axis=0)  # degree of confidence\n",
    "\n",
    "        if prediction == 'me':\n",
    "            color = GREEN\n",
    "        else:\n",
    "            color = RED\n",
    "        # draw a rectangle around the face\n",
    "        cv2.rectangle(frame,\n",
    "                      (x, y),  # start_point\n",
    "                      (x+w, y+h),  # end_point\n",
    "                      color,\n",
    "                      2)  # thickness in px\n",
    "        cv2.putText(frame,\n",
    "                    # text to put\n",
    "                    \"{:6} - {:.2f}%\".format(prediction, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    2,  # fontScale\n",
    "                    color,\n",
    "                    2)  # thickness in px\n",
    "\n",
    "    # display the resulting frame\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27:  # ESC code\n",
    "        break\n",
    "\n",
    "\n",
    "# when everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88cf98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc8474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
